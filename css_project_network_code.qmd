git---
title: "CSS Project"
format: html
---

#### Main Code

Loading packages

```{r}
library(tidyverse)
library(tidygraph)
library(igraph)
library(ggraph)
library(here)
library(ideanet)
library(arrow)
```

Load tables

```{r}
coauthors <- readRDS(here("coauthor_pairs_final.rds"))
researchers <- readRDS(here("researcher_df.rds"))

researcher_embeddings <- read_feather(here("Embedding/researcher_df_with_emb_new.feather"))

#loading adjacency matrix of similarity scores
similarity_data <- read_feather(here("Embedding/similarity_id_df.feather"))
similarity_data <- similarity_data %>% 
  remove_rownames() %>% 
  column_to_rownames(var = "researcher_id")
```

Creating a network from an adjacency matrix of similarity scores

```{r}
#creating adjacency matrix
adjacency_matrix <- as.matrix(similarity_data)

#removing self-loops
diag(adjacency_matrix) <- 0

isSymmetric(adjacency_matrix)

#Creating network
network <- graph_from_adjacency_matrix(adjacency_matrix, weighted = TRUE, mode = "undirected")
```

Adding traits to the nodes

```{r}
researchers_in_data <- researcher_embeddings %>% 
  select(researcher_id) %>% 
  left_join(researchers, by = "researcher_id")

V(network)$discipline <- researchers_in_data$department_raw
V(network)$rank <- researchers_in_data$role
V(network)$full_name <- researchers_in_data$full_name
V(network)$id <- V(network)$name
```

Making computationally easier

```{r}
#turning the network into a tibble
network_graph_large <- as_tbl_graph(network)

#creating an edge only network
edges_network_large <- network_graph_large %>% 
  activate(edges) %>% 
  as_tibble()

#creating a node only network
nodes_network_large <- network_graph_large %>% 
  activate(nodes) %>% 
  as_tibble()
```

Weights

```{r}
#keeping top n edges (can adjust n depending on how dense you want the network to be)
network_graph_modified <- network_graph_large %>% 
  activate(edges) %>% 
  group_by(from) %>% 
  slice_max(weight, n = 10, with_ties = FALSE) %>% 
  ungroup() %>% 
  filter(weight > 0)

#checking the structure of the new network
count_components(network_graph_modified)
is_connected(network_graph_modified)
components <- components(network_graph_modified)
degree(network_graph_modified)
vcount(network_graph_modified)
gsize(network_graph_modified)

#running a test of various resolutions to look at stable community sizes
resolutions <- seq(0.1, 4, by = 0.05)
communities_test <- c()
modularities <- c()

for(resolution in resolutions) {
  no_coms <- c()
  mods <- c()
  for(i in 1:25) {
    lc_test <- cluster_louvain(network_graph_modified,
                             weights = network_graph_modified %>% activate(edges) %>% pull(weight),
                             resolution = resolution)
    mod <- modularity(lc_test)
    mods <- c(mods, mod)
    no_com <- max(lc_test$membership)
    no_coms <- c(no_coms, no_com)
  }
  avg_com <- mean(no_coms)
  communities_test <- c(communities_test, avg_com)
  avg_mod <- mean(mods)
  modularities <- c(modularities, avg_mod)
}
communities <- round(communities_test)
plot(resolutions, communities)
plot(resolutions, modularities)
setNames(communities, resolutions)

#clustering the network by Louvain with a stable resolution (can change the resolution depending on the desired fine-grainedness of the communities, and on the desired modularity)
network_clusters <- cluster_louvain(network_graph_modified,
                                    weights = network_graph_modified %>% activate(edges) %>% pull(weight),
                                    resolution = 3.45)
print(network_clusters)

#assigning membership based on clusters, adding betweenness centrality to identify high level betweenness nodes
network_graph_modified <- network_graph_modified %>%
  activate(nodes) %>%
  mutate(membership = membership(network_clusters)) %>% 
  mutate(betweenness = betweenness(network_graph_modified))
```

Creating an edge and node only tibble

```{r}
#creating an edge only network
edges_network <- network_graph_modified %>% 
  activate(edges) %>% 
  as_tibble()

#creating a node only network
nodes_network <- network_graph_modified %>% 
  activate(nodes) %>% 
  as_tibble()

#checking the communities are meaningful (make sure same number of rows as communities, can adjust filter count)
community_structure <- nodes_network %>% 
  group_by(membership, discipline) %>% 
  summarize(count = n()) %>% 
  filter(count > 5) %>% 
  group_by(membership) %>% 
  summarize(community_name = paste(discipline, collapse = " & "))

community_structure_names <- setNames(community_structure$community_name, community_structure$membership)
```

Filter method (need to watch out for same names, if possible, run everything by ID number, then switch to names at the end based on ID and name associations)

```{r}
#duplicating the network so that _to connections are accounted for (in other words because it is undirected, to and from connections are the same, so both directions need to be included, otherwise some researchers will only show up in the two column when they equally need to be analyzed as the rest of the analysis draws from the from column)
edges_network_2 <- edges_network %>% 
  rename(to_2 = from) %>% 
  rename(from = to) %>% 
  rename(to = to_2)

edges_network <- rbind(edges_network, edges_network_2)

#combining the node information into the edge network
matching_tibble <- edges_network %>% 
  left_join(nodes_network %>% 
              mutate(from = row_number()), by = "from") %>% 
  left_join(nodes_network %>% 
              mutate(to = row_number()), by = "to") %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#filtering out any edges that are in the same community or discipline
match_filter <- matching_tibble %>% 
  filter(membership_from != membership_to) %>% 
  filter(discipline_from != discipline_to)

#filtering out previously collaborated
match_filter <- match_filter %>% 
  anti_join(coauthors, by = c("name_from" = "researcher_A_id", "name_to" = "researcher_B_id")) %>% 
  anti_join(coauthors, by = c("name_from" = "researcher_B_id", "name_to" = "researcher_A_id"))

#duplicating match_filter so that the _to nodes also are accounted for

#generating a list of each individuals matches (based on similarity)
matching_similarity <- match_filter %>% 
  group_by(name_from, full_name_from) %>% 
  arrange(desc(weight)) %>% 
  summarize(sim_neighbors = list(name_to), weights = list(weight), .groups = "drop")

#generating a list of each individuals matches (based on betweenness or bridges)
matching_betweenness <- match_filter %>% 
  group_by(name_from, full_name_from) %>% 
  arrange(desc(betweenness_to)) %>% 
  summarize(betw_neighbors = list(name_to), weights = list(weight), .groups = "drop")

#adding in the top matching collaborator for each individual (based on similarity)
matching_similarity_list <- matching_similarity %>% 
  mutate(betw_neighbors = matching_betweenness$betw_neighbors) %>% 
  mutate(number_possible_collabs = map(sim_neighbors, length)) %>% 
  mutate(top_sim_neighbor = map(sim_neighbors, first)) %>% 
  mutate(top_betw_neighbor = map(betw_neighbors, first)) %>% 
  mutate(weight = map(weights, first)) %>% 
  unnest(weight) %>% 
  unnest(top_sim_neighbor) %>% 
  unnest(top_betw_neighbor) %>% 
  unnest(number_possible_collabs) %>% 
  relocate(top_sim_neighbor, .before = "sim_neighbors") %>% 
  relocate(top_betw_neighbor, .after = "betw_neighbors")

#adding and organizing information based on the top collaborators
matching_similarity_list <- matching_similarity_list %>% 
  rename(name = name_from) %>% 
  left_join(nodes_network, by = "name") %>% 
  select(-c(id, full_name_from)) %>% 
  rename(id = top_sim_neighbor) %>% 
  left_join(nodes_network, by = "id") %>% 
  select(-id) %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#keeping only matches where they match to each other (unfortunately none as of yet)
match_similarity_mates <- matching_similarity_list %>%
  select(name_from, name_to) %>% 
  rowwise() %>%
  mutate(pair_key = paste(sort(c(name_from, name_to)), collapse = "_")) %>%
  ungroup() %>%
  group_by(pair_key) %>%
  filter(n() > 1) %>% 
  ungroup() %>% 
  select(-pair_key)

#perfect match full table (contains each pairing twice)
match_similarity_mates <- match_similarity_mates %>% 
  left_join(nodes_network %>% 
              rename(name_from = name), by = "name_from") %>% 
  left_join(nodes_network %>% 
              rename(name_to = name), by = "name_to") %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#checking for where top betweenness and top similarity are the same
betweenness_similarity <- matching_similarity_list %>% 
  filter(name_to == top_betw_neighbor)

#adding in the top matching collaborator for each individual (based on betweenness)
matching_betweenness_list <- matching_betweenness %>% 
  mutate(sim_neighbors = matching_similarity$sim_neighbors) %>% 
  mutate(number_possible_collabs = map(sim_neighbors, length)) %>% 
  mutate(top_sim_neighbor = map(sim_neighbors, first)) %>% 
  mutate(top_betw_neighbor = map(betw_neighbors, first)) %>% 
  mutate(weight = map(weights, first)) %>% 
  unnest(weight) %>% 
  unnest(top_sim_neighbor) %>% 
  unnest(top_betw_neighbor) %>% 
  unnest(number_possible_collabs) %>% 
  relocate(top_betw_neighbor, .before = "betw_neighbors") %>% 
  relocate(top_sim_neighbor, .after = "weight")

#adding and organizing information based on the top collaborators
matching_betweenness_list <- matching_betweenness_list %>% 
  rename(name = name_from) %>% 
  left_join(nodes_network, by = "name") %>% 
  select(-c(id, full_name_from)) %>% 
  rename(id = top_betw_neighbor) %>% 
  left_join(nodes_network, by = "id") %>% 
  select(-id) %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#keeping only matches where they match to each other
match_betweeness_mates <- matching_betweenness_list %>%
  select(name_from, name_to) %>% 
  rowwise() %>%
  mutate(pair_key = paste(sort(c(name_from, name_to)), collapse = "_")) %>%
  ungroup() %>%
  group_by(pair_key) %>%
  filter(n() > 1) %>% 
  ungroup() %>% 
  select(-pair_key)

#perfect match full table (contains each pairing twice)
match_betweeness_mates <- match_betweeness_mates %>% 
  left_join(nodes_network %>% 
              rename(name_from = name), by = "name_from") %>% 
  left_join(nodes_network %>% 
              rename(name_to = name), by = "name_to") %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

```

Visuals

```{r}
#preliminary visualization
network_visual <- ggraph(network_graph_modified, layout = "fr") +
  geom_edge_link(alpha = 0.1) +
  geom_node_point(aes(color = as.factor(membership)), size = 0.5)

network_visual + scale_color_discrete(labels = community_structure_names) + theme(legend.text = element_text(size = 3))

```

#### Code That Isn't Used

```{r}
#publications <- readRDS(here("publication_clean_df.rds"))
#similarity_data <- read.csv(here("Code/professor_similarity_matrix.csv"), row.names = 1)
```

```{r}
# weights <- edges_network_large$weight
# 
# #setting proximity threshold (based on sum of edge density over number of edges, so mean density)
# proximity_threshold <- sum(weights)/ecount(network)
# prox_thres_var <- quantile(weights, 0.9)

# #modifying the network to only have ties above the mean
# network_graph_modified <- network_graph_large %>% 
#   activate(edges) %>% 
#   filter(weight > proximity_threshold) 

# #modying the network so it is one connected component
# network_graph_modified <- network_graph_modified %>%
#   activate(nodes) %>%
#   mutate(component = components$membership) %>%
#   filter(component == 1)
```

Alternative partition method (more precise to get resolutions but the network is too computationally large for this function)

```{r}
# partitions <- get_partitions(network_modified)
# 
# #needs to be assigned to the same object as the partitions object
# partitions <- CHAMP(network_modified, partitions)
# 
# partitions <- get_CHAMP_map(network_modified, partitions)

#set resolution manually based on partitions object
# network_clusters <- cluster_louvain(network_modified, resolution = 0.63) 
# 
# #assigning membership based on clusters
# V(network_modified)$community <- membership(network_clusters)
```


Paths or walks (of length 2) (probably won't use)

```{r}
# nodes <- V(network_modified)$name
# 
# all_paths <- list()
# 
# for (node in nodes) {
#   paths <- all_simple_paths(network_modified, node, cutoff = 2)
#   end_nodes <- character(0)
#   for (path in paths) {
#     path_names <- V(network_modified)$name[as.numeric(path)]
#     end_nodes <- c(end_nodes, tail(path_names, 1))
#     end_nodes <- unique(end_nodes)
#     }
#   all_paths[[node]] <- end_nodes
# }
```

Once this list of end nodes is created, need to decide what the optimal collaboration threshold of similarity is
- Is path length of 2 best?
- What should the collaboration threshold be? It should be under the similarity threshold but over another amount. - Is the edge matching threshold too low?


