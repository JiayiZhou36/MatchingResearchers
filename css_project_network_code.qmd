git---
title: "CSS Project"
format: html
---

Loading packages

```{r}
library(tidyverse)
library(tidygraph)
library(igraph)
library(ggraph)
library(here)
library(ideanet)
library(arrow)
```

Load tables

```{r}
#publications <- readRDS(here("publication_clean_df.rds"))
coauthors <- readRDS(here("coauthor_pairs_final.rds"))
researchers <- readRDS(here("researcher_df.rds"))

researcher_embeddings <- read_feather(here("Embedding/researcher_df_with_emb_new.feather"))

#loading adjacency matrix of similarity scores
#similarity_data <- read.csv(here("Code/professor_similarity_matrix.csv"), row.names = 1)
similarity_data <- read_feather(here("Embedding/similarity_id_df.feather"))
similarity_data <- similarity_data %>% 
  remove_rownames() %>% 
  column_to_rownames(var = "researcher_id")
```

Creating a network from an adjacency matrix of similarity scores

```{r}
#creating adjacency matrix
adjacency_matrix <- as.matrix(similarity_data)

#removing self-loops
diag(adjacency_matrix) <- 0

isSymmetric(adjacency_matrix)

#Creating network
network <- graph_from_adjacency_matrix(adjacency_matrix, weighted = TRUE, mode = "undirected")
```

Adding traits to the nodes

```{r}
researchers_in_data <- researcher_embeddings %>% 
  select(researcher_id) %>% 
  left_join(researchers, by = "researcher_id")

V(network)$discipline <- researchers_in_data$department_raw
V(network)$rank <- researchers_in_data$role
V(network)$full_name <- researchers_in_data$full_name
V(network)$id <- V(network)$name
```

Making computationally easier

```{r}
#turning the network into a tibble
network_graph_large <- as_tbl_graph(network)

#creating an edge only network
edges_network_large <- network_graph_large %>% 
  activate(edges) %>% 
  as_tibble()

#creating a node only network
nodes_network_large <- network_graph_large %>% 
  activate(nodes) %>% 
  as_tibble()
```

Weights

```{r}
weights <- edges_network_large$weight

#setting proximity threshold (based on sum of edge density over number of edges, so mean density)
proximity_threshold <- sum(weights)/ecount(network)
prox_thres_var <- quantile(weights, 0.9)
  
#modifying the network to only have ties above the mean
network_graph_modified <- network_graph_large %>% 
  activate(edges) %>% 
  filter(weight > prox_thres_var) 

# components <- components(network_graph_modified)
count_components(network_graph_modified)
mean(degree(network_graph_modified))

# network_graph_modified <- network_graph_modified %>%
#   activate(nodes) %>%
#   mutate(component = components$membership) %>%
#   filter(component == 1)
# 
# is_connected(network_graph_modified)

# weights <- network_graph_modified %>%
#   activate(edges) %>%
#   pull(weight)
# proximity_threshold <- sum(weights)/length(weights)
# 
# network_graph_modified <- network_graph_modified %>%
#   activate(edges) %>%
#   filter(weight > proximity_threshold)
# 
# components <- components(network_graph_modified)
# count_components(network_graph_modified)
# 
# network_graph_modified <- network_graph_modified %>%
#   activate(nodes) %>%
#   mutate(component = components$membership) %>%
#   filter(component == 1)
# 
# is.connected(network_graph_modified)

# resolutions <- seq(0.1, 4, by = 0.1)
# communities_test <- c()
# modularities <- c()
# 
# for(resolution in resolutions) {
#   lc_test <- cluster_louvain(network_graph_modified,
#                              weights = network_graph_modified %>% activate(edges) %>% pull(weight), 
#                              resolution = resolution)
#   modularity <- modularity(lc_test)
#   modularities <- c(modularities, modularity)
#   no_com <- max(lc_test$membership)
#   communities_test <- c(communities_test, no_com)
# }
# 
# plot(resolutions, communities_test)
# plot(resolution, modularities)

network_clusters <- cluster_louvain(network_graph_modified,
                                    weights = network_graph_modified %>% activate(edges) %>% pull(weight),
                                    resolution = 3)
print(network_clusters)
modularity(network_clusters)

#assigning membership based on clusters
network_graph_modified <- network_graph_modified %>%
  activate(nodes) %>%
  mutate(membership = membership(network_clusters))
```

Clustering (see above)

```{r}
# partitions <- get_partitions(network_modified)
# 
# #needs to be assigned to the same object as the partitions object
# partitions <- CHAMP(network_modified, partitions)
# 
# partitions <- get_CHAMP_map(network_modified, partitions)

#set resolution manually based on partitions object
# network_clusters <- cluster_louvain(network_modified, resolution = 0.63) 
# 
# #assigning membership based on clusters
# V(network_modified)$community <- membership(network_clusters)
```

Filter method (need to watch out for same names, if possible, run everything by ID number, then switch to names at the end based on ID and name associations)

```{r}
#creating an edge only network
edges_network <- network_graph_modified %>% 
  activate(edges) %>% 
  as_tibble()

#creating a node only network
nodes_network <- network_graph_modified %>% 
  activate(nodes) %>% 
  as_tibble()

#combining the node information into the edge network
matching_tibble <- edges_network %>% 
  left_join(nodes_network %>% 
              mutate(from = row_number()), by = "from") %>% 
  left_join(nodes_network %>% 
              mutate(to = row_number()), by = "to") %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#filtering out any edges that are in the same community, discipline
matching_test <- matching_tibble %>% 
  filter(membership_from != membership_to) %>% 
  filter(discipline_from != discipline_to)

#filtering out previously collaborated
matching_test <- matching_test %>% 
  anti_join(coauthors, by = c("name_from" = "researcher_A_id", "name_to" = "researcher_B_id")) %>% 
  anti_join(coauthors, by = c("name_from" = "researcher_B_id", "name_to" = "researcher_A_id"))

#generating a list of each individuals matches
matching_list <- matching_test %>% 
  group_by(name_from, full_name_from) %>% 
  arrange(desc(weight)) %>% 
  summarize(neighbors = list(name_to), weights = list(weight), .groups = "drop")

#adding in the top matching collaborator for each individual
matching_list <- matching_list %>% 
  mutate(number_possible_collabs = map(neighbors, length)) %>% 
  mutate(top_neighbor = map(neighbors, first)) %>% 
  mutate(weight = map(weights, first)) %>% 
  unnest(weight) %>% 
  unnest(top_neighbor) %>% 
  unnest(number_possible_collabs) %>% 
  relocate(top_neighbor, .before = "neighbors")

matching_list <- matching_list %>% 
  rename(name = name_from) %>% 
  left_join(nodes_network, by = "name") %>% 
  select(-c(id, full_name_from)) %>% 
  rename(id = top_neighbor) %>% 
  left_join(nodes_network, by = "id") %>% 
  select(-id) %>% 
  rename_with(\(x) gsub("\\.x", "_from", x)) %>% 
  rename_with(\(x) gsub("\\.y", "_to", x))

#keeping only matches where they match to each other
match_mates <- matching_list %>%
  select(name_from, name_to) %>% 
  rowwise() %>%
  mutate(pair_key = paste(sort(c(name_from, name_to)), collapse = "_")) %>%
  ungroup() %>%
  group_by(pair_key) %>%
  filter(n() > 1) %>% 
  ungroup() %>% 
  select(-pair_key)
  
#join by ID and researcher name tibble with matching tibble to get the right person and the right names
```

Visuals (to be built up for paper) (not useful right now)

```{r}
#preliminary visualization
# ggraph(network_modified, layout = "fr") +
#   geom_edge_link(alpha = 0.5) +
#   geom_node_point(aes(color = as.factor(community)), size = 3)
# 
# plot(network_clusters, network_modified)
```

Paths or walks (of length 2) (probably won't use)

```{r}
# nodes <- V(network_modified)$name
# 
# all_paths <- list()
# 
# for (node in nodes) {
#   paths <- all_simple_paths(network_modified, node, cutoff = 2)
#   end_nodes <- character(0)
#   for (path in paths) {
#     path_names <- V(network_modified)$name[as.numeric(path)]
#     end_nodes <- c(end_nodes, tail(path_names, 1))
#     end_nodes <- unique(end_nodes)
#     }
#   all_paths[[node]] <- end_nodes
# }
```

Once this list of end nodes is created, need to decide what the optimal collaboration threshold of similarity is
- Is path length of 2 best?
- What should the collaboration threshold be? It should be under the similarity threshold but over another amount. - Is the edge matching threshold too low?


