{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89083c0d-17e1-4fbd-8045-43b4365a08a3",
   "metadata": {},
   "source": [
    "Data design:\n",
    "This code is for basic data design and cleaning. The objective is to generate three tables from the raw full dataset-JSON data. \n",
    "\n",
    "We plan to generate three tables from the raw JSON data:\n",
    "\n",
    "1. Researcher table: researcher_df \n",
    "This table contains one row per researcher.\n",
    "Required fields include: \n",
    "\"researcher_id\": a unique identifier for each researcher; \n",
    "\"first_name\"; \n",
    "\"last_name\"; \n",
    "\"email\"; \n",
    "\"title\"; \n",
    "\"overview\":\n",
    "\"department_raw\" (parsed from the title directly before cleaning); \n",
    "\"role\": the role of this research in Duke University(for example, professor, assistant professor, graduate student, etc.)The role field for each researcher is determined through a two-stage extraction pipeline. The general principle is: use the primaryAppointment.title first; if that fails, fall back to parsing the overview text. All matching is case-insensitive unless otherwise specified.\n",
    "pub_count: the overall amounts of publication of this researcher;\n",
    "latest_pub_date: the newest publication date.\n",
    "\n",
    "\n",
    "2. Publication table: publication_clean_df \n",
    "****** There are a total of 481,572 author–publication rows, but the number of orginal pub_id(pulled out directly from duke database)'s  values is also 481,572. This means that each pub_id appears only once, and there is no case where two authors share the same pub_id. Therefore, pub_id cannot be used as an indicator of co-authorship, because it does not represent shared publications among multiple researchers. \n",
    "\n",
    "****** In this case, use \"title to create unique_ids and coauthor pairs. (After testing, there is no missing in titles)\n",
    "\n",
    "this table contains one row per publication.\n",
    "Required fields include:\n",
    "\n",
    "\"pub_unique_id\": the unique_id we created by titles. \n",
    "\"researcher_id\": researcher_id,\n",
    "\"researcher_full_name\": first_name,\n",
    "\"pub_title\": pub_title,\n",
    "\"pub_abstract\": pub_abstract,\n",
    "\"pub_doi\": pub_doi,\n",
    "\"duke_authors\": All Duke-affiliated authors matched from the Duke researcher database.\n",
    "\"raw_pub_ids\": All original pub_id values associated with this publication in the Duke source data.\n",
    "\"all_authors\": all_authors, including people who are not matched via Duke database,\n",
    "\"pub_date\": the date this research was published. \n",
    "\n",
    "\n",
    "3. Coauthor relationship: coauthor_pairs_final  \n",
    "This table contains one row per co-author pair. \n",
    "Based on the unique_ids we used \"title\" to create, we created the deduplicated author.\n",
    "Required fields include:\n",
    "Researcher_A_id,\n",
    "Researcher_B_id,\n",
    "Researcher_A_name,\n",
    "Researcher_B_name,\n",
    "joint_pub_numbers: how many publications they collaborated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ad6a8e-9cc6-4912-8f39-9fb2be5b3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nanoid in /opt/anaconda3/lib/python3.13/site-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "!pip install nanoid\n",
    "from nanoid import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432bab4-2b96-4bfb-aa30-fb52bbd41890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import json\n",
    "\n",
    "with open(\"people_2025-11-25_13-57-52.json\", \"r\") as f:\n",
    "    data_dict = json.load(f)\n",
    "data = data_dict[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626feb98-271c-4cb6-bfca-91939d98b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data strcuture\n",
    "def print_json_structure(d, indent=0):\n",
    "    prefix = \"  \" * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f\"{prefix}{k}: ({type(v).__name__})\")\n",
    "            print_json_structure(v, indent + 1)\n",
    "    elif isinstance(d, list):\n",
    "        print(f\"{prefix}[list of length {len(d)}]\")\n",
    "        if len(d) > 0:\n",
    "            print_json_structure(d[0], indent + 1)\n",
    "    else:\n",
    "        # primitive value -> 不展开\n",
    "        print(f\"{prefix}{d} ({type(d).__name__})\")\n",
    "\n",
    "print_json_structure(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2ffc5-aecd-4064-9503-2ab2b3fb39e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need to figure out what the 'currentResearch' refers to.\n",
    "for i in range(10):\n",
    "    print(data[i]['currentResearch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00895b2d-7221-4654-87de-41830af69027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2c2dd-54a9-4b9e-a383-d32979c17503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate unique researcher id. \n",
    "from nanoid import generate  # make sure nanoid is installed: pip install nanoid\n",
    "\n",
    "# data is already a list of researchers\n",
    "print(type(data), len(data))  # just to confirm\n",
    "\n",
    "for person in data:\n",
    "    person[\"unique_id\"] = generate(size=12)  # e.g. \"a8Gs93KdL0pQ\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ae9a963-a6c4-432b-9b3e-6a1dc80a5877",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Role Extraction Logic \n",
    "\n",
    "The role field for each researcher is determined through a two-stage extraction pipeline. The general principle is:\n",
    "use the primaryAppointment.title first; if that fails, fall back to parsing the overview text.\n",
    "All matching is case-insensitive unless otherwise specified.\n",
    "    1. Extraction from primaryAppointment.title (Primary Source)\n",
    "\n",
    "If a researcher has a non-empty primaryAppointment.title, this field is treated as the most reliable indicator of academic rank or position.\n",
    "The title is normalized to lowercase, and the following ordered rules are applied:\n",
    "\n",
    "(1) Emeritus/Emerita detection (highest priority)\n",
    "\n",
    "If the title contains “emeritus” or “emerita”, the role is assigned accordingly (e.g., \"Professor Emeritus\").\n",
    "\n",
    "(2) Visiting appointments\n",
    "\n",
    "If the title includes “visiting”, the role becomes either:\n",
    "\n",
    "\"Visiting Professor\" (if “professor” also appears), or\n",
    "\n",
    "\"Visiting Faculty\" (otherwise).\n",
    "\n",
    "(3) In Residence roles\n",
    "\n",
    "Titles containing “in residence” are categorized based on preceding keywords such as:\n",
    "\n",
    "\"Executive in Residence\"\n",
    "\n",
    "\"Artist in Residence\"\n",
    "\n",
    "\"Scholar in Residence\"\n",
    "\n",
    "(4) Standard faculty ranks\n",
    "\n",
    "Roles are assigned based on the presence of specific rank descriptors:\n",
    "\n",
    "\"Associate Professor\"\n",
    "\n",
    "\"Assistant Professor\"\n",
    "\n",
    "\"Professor\"\n",
    "\n",
    "\"Clinical Professor\" / \"Clinical Faculty\"\n",
    "\n",
    "\"Research Professor\"\n",
    "\n",
    "\"Adjunct Professor\"\n",
    "The matching is done in a prioritized order (associate > assistant > professor, etc.).\n",
    "\n",
    "(5) Lecturer / Instructor / Fellow\n",
    "\n",
    "If none of the above apply, roles may be assigned based on:\n",
    "\n",
    "\"Lecturer\" or \"Lecturing Fellow\"\n",
    "\n",
    "\"Instructor\"\n",
    "\n",
    "(6) Fallback\n",
    "\n",
    "If no rule matches, the role remains None and the overview text is used in the next stage.\n",
    "\n",
    "2. Extraction from overview (Fallback Source)\n",
    "\n",
    "If the role is still None after title-based matching, the researcher’s overview text is parsed using case-insensitive regular expressions. The extraction follows a priority order to prevent overly broad matches (such as “student”) from overriding more specific roles.\n",
    "\n",
    "Priority order for overview-based extraction:\n",
    "(1) PhD-level graduate roles\n",
    "\n",
    "Detected via patterns such as:\n",
    "\n",
    "\"Ph.D. Candidate\"\n",
    "\n",
    "\"PhD Candidate\"\n",
    "\n",
    "\"PhD Student\"\n",
    "\n",
    "\"Doctoral Student\"\n",
    "These all map to:\n",
    "\"PhD Candidate\"\n",
    "\n",
    "(2) Graduate Student\n",
    "\n",
    "Matches \"Graduate Student\" → \"Graduate Student\"\n",
    "\n",
    "(3) Director (capital D only)\n",
    "\n",
    "To avoid false positives, only \"Director\" with capital D is matched → \"Director\"\n",
    "\n",
    "(4) Student (lowest priority)\n",
    "\n",
    "As the final fallback, occurrences of \"student\" assign:\"Student\"\n",
    "\n",
    "This rule is only evaluated if none of the more specific patterns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d8144-da22-4be2-a8b1-11c2ffe5fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role extraction from \"PrimaryAppionment[title]\n",
    "\n",
    "import re\n",
    "\n",
    "def get_role_phrase(raw_title: str):\n",
    "    \"\"\"Extract the role phrase before 'in/of/at' or comma.\"\"\"\n",
    "    if not raw_title:\n",
    "        return None\n",
    "    t = raw_title.strip()\n",
    "    m = re.match(r'^(.*?)(?:\\s+(?:in|of|at)\\b|,)', t, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def normalize_role(raw_title: str):\n",
    "    \"\"\"Normalize academic role titles into a standard label.\"\"\"\n",
    "    if not raw_title:\n",
    "        return None\n",
    "    \n",
    "    # Step 1: extract core role phrase\n",
    "    t = get_role_phrase(raw_title)\n",
    "    if not t:\n",
    "        return None\n",
    "    s = t.strip()\n",
    "\n",
    "    # --- Matching rules in priority order ---\n",
    "\n",
    "    # Emeritus/Emerita\n",
    "    if re.search(r'\\bProfessor\\b.*\\bEmerit', s, flags=re.I):\n",
    "        return 'Professor Emeritus'\n",
    "\n",
    "    # Professor of the Practice\n",
    "    if re.search(r'\\bProfessor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Professor of the Practice'\n",
    "    if re.search(r'\\bAssociate\\s+Professor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Associate Professor of the Practice'\n",
    "    if re.search(r'\\bAssistant\\s+Professor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Assistant Professor of the Practice'\n",
    "\n",
    "    # Special prefixes\n",
    "    if re.search(r'\\bAdjunct\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Adjunct Professor'\n",
    "    if re.search(r'\\bClinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Clinical Professor'\n",
    "    if re.search(r'\\bResearch\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Research Professor'\n",
    "    if re.search(r'\\bVisiting\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Visiting Professor'\n",
    "    \n",
    "    # Medical titles\n",
    "    if re.search(r'\\bMedical\\s+Assistant\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Assistant Professor'\n",
    "    if re.search(r'\\bMedical\\s+Associate\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Associate Professor'\n",
    "    if re.search(r'\\bMedical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Professor'\n",
    "\n",
    "    # Standard professor ranks\n",
    "    if re.search(r'\\bAssociate\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Associate Professor'\n",
    "    if re.search(r'\\bAssistant\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Assistant Professor'\n",
    "    if re.search(r'\\bProfessor\\b', s, flags=re.I):\n",
    "        return 'Professor'\n",
    "\n",
    "    # Clinical roles\n",
    "    if re.search(r'\\bClinical\\s+Faculty\\b', s, flags=re.I):\n",
    "        return 'Clinical Faculty'\n",
    "    if re.search(r'\\bAssociate\\s+Clinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Associate Clinical Professor'\n",
    "    if re.search(r'\\bAssistant\\s+Clinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Assistant Clinical Professor'\n",
    "    if re.search(r'\\bClinical\\s+Associate\\b', s, flags=re.I):\n",
    "        return 'Clinical Associate'\n",
    "    if re.search(r'\\bClinical\\s+Affiliate\\b', s, flags=re.I):\n",
    "        return 'Clinical Affiliate'\n",
    "\n",
    "    # Lecturer / Fellow\n",
    "    if re.search(r'\\bSenior\\s+Lecturing\\s+Fellow\\b', s, flags=re.I):\n",
    "        return 'Senior Lecturing Fellow'\n",
    "    if re.search(r'\\bLecturing\\s+Fellow\\b', s, flags=re.I):\n",
    "        return 'Lecturing Fellow'\n",
    "    if re.search(r'\\bSenior\\s+Lecturer\\b', s, flags=re.I):\n",
    "        return 'Senior Lecturer'\n",
    "    if re.search(r'\\bLecturer\\b', s, flags=re.I):\n",
    "        return 'Lecturer'\n",
    "\n",
    "    # Instructor family\n",
    "    if re.search(r'\\bMedical\\s+Instructor\\b', s, flags=re.I):\n",
    "        return 'Medical Instructor'\n",
    "    if re.search(r'\\bInstructor\\b', s, flags=re.I):\n",
    "        return 'Instructor'\n",
    "\n",
    "    # In Residence / Artist in Residence / Scholar in Residence\n",
    "    if re.search(r'\\bExecutive\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Executive in Residence'\n",
    "    if re.search(r'\\bArtist\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Artist in Residence'\n",
    "    if re.search(r'\\bScholar\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Scholar in Residence'\n",
    "\n",
    "    # Fallback: return original phrase\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64ea04-e47f-4fa0-b554-2d8bb7d847df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: extract title from primaryAppointment\n",
    "def extract_pa_title(pa):\n",
    "    if isinstance(pa, dict):\n",
    "        return pa.get(\"title\")\n",
    "    return None\n",
    "\n",
    "# Step 2: add the new field to each researcher dict\n",
    "for person in data:   # data is your full JSON list\n",
    "    pa_title = extract_pa_title(person.get(\"primaryAppointment\"))\n",
    "    role = normalize_role(pa_title)  # use the function we defined earlier\n",
    "    person[\"role\"] = role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5b3f0-0f41-4d6d-9fe1-941ec7486a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the role is null, continue to fill the role with \"overview\"\n",
    "\n",
    "import re\n",
    "\n",
    "# 1. Regex pattern for roles in overview (case-insensitive)\n",
    "role_pattern_overview = re.compile(\n",
    "    r\"(\"\n",
    "    r\"ph\\.?d\\.?\\s*candidate|\"        # PhD Candidate / Ph.D. Candidate / phd candidate\n",
    "    r\"doctoral\\s+student|\"           # Doctoral Student\n",
    "    r\"graduate\\s+student|\"           # Graduate Student\n",
    "    r\"\\bdirector\\b|\"                 # Director\n",
    "    r\"\\bstudent\\b\"                   # Student (fallback; used only if nothing else matched)\n",
    "    r\")\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# 2. Fill role from overview ONLY when existing role is None\n",
    "filled_from_overview = 0\n",
    "\n",
    "for person in data:\n",
    "    # Only try overview if role is currently None\n",
    "    if person.get(\"role\") is None:\n",
    "        overview = person.get(\"overview\") or \"\"\n",
    "        \n",
    "        # Search in overview text\n",
    "        match = role_pattern_overview.search(overview)\n",
    "        if match:\n",
    "            # Use the matched string as role (keep original casing from overview)\n",
    "            person[\"role\"] = match.group(0).strip()\n",
    "            filled_from_overview += 1\n",
    "\n",
    "print(\"Number of roles filled from overview:\", filled_from_overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3d3f5-5bea-4e43-ba4c-d9f580c0efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# department/major \n",
    "import re\n",
    "\n",
    "def extract_department_from_title(primary_appointment):\n",
    "    \"\"\"\n",
    "    primary_appointment is either:\n",
    "      - None\n",
    "      - dict like {\"title\": \"Assistant Professor in ...\"}\n",
    "    \"\"\"\n",
    "    # 1. If no primaryAppointment\n",
    "    if primary_appointment is None:\n",
    "        return None\n",
    "    \n",
    "    # 2. Extract string from {\"title\": \"...\"} \n",
    "    if isinstance(primary_appointment, dict):\n",
    "        title = primary_appointment.get(\"title\", None)\n",
    "    else:\n",
    "        # fallback: if it's already a string\n",
    "        title = primary_appointment\n",
    "    \n",
    "    if not isinstance(title, str):\n",
    "        return None\n",
    "    \n",
    "    t = title.strip()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    lower = t.lower()\n",
    "\n",
    "    # --- extraction rules ---\n",
    "    idx_in = lower.rfind(\" in \")\n",
    "    if idx_in != -1:\n",
    "        dept = t[idx_in + len(\" in \"):].strip()\n",
    "    else:\n",
    "        idx_of = lower.rfind(\" of \")\n",
    "        if idx_of != -1:\n",
    "            dept = t[idx_of + len(\" of \"):].strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # remove \"the \"\n",
    "    dept = re.sub(r\"^\\s*the\\s+\", \"\", dept, flags=re.IGNORECASE)\n",
    "\n",
    "    # remove prefixes\n",
    "    dept = re.sub(r\"^(Department|Division|School|Program|Centre|Center)\\s+of\\s+\", \"\", dept, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # Handle \"Department of X\" inside string\n",
    "    m = re.search(r\"Department\\s+of\\s+(.+)\", dept, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        dept = m.group(1).strip()\n",
    "\n",
    "    # Handle \"School of Nursing\" → \"Nursing\"\n",
    "    m2 = re.search(r\"School\\s+of\\s+(.+)\", dept, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        dept = m2.group(1).strip()\n",
    "\n",
    "    return dept if dept else None\n",
    "\n",
    "\n",
    "# --- Attach to your data ---\n",
    "for person in data:\n",
    "    person[\"department_raw\"] = extract_department_from_title(person.get(\"primaryAppointment\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34bdde-d2fd-4a09-b460-3b384b23e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate table one: researcher table \n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for person in data:   # data is your list of 11547 researchers\n",
    "\n",
    "    # 1. unique researcher id\n",
    "    rid = person.get(\"unique_id\")\n",
    "\n",
    "    # 2. name fields\n",
    "    first = person.get(\"firstName\")\n",
    "    last = person.get(\"lastName\")\n",
    "    full = f\"{first} {last}\".strip() if first or last else None\n",
    "\n",
    "    # 3. email\n",
    "    email = person.get(\"email\")\n",
    "\n",
    "    # 4. primary appointment title\n",
    "    pa = person.get(\"primaryAppointment\")\n",
    "    if isinstance(pa, dict):\n",
    "        title = pa.get(\"title\")\n",
    "    else:\n",
    "        title = None\n",
    "\n",
    "    # 5. department_raw from your earlier extraction\n",
    "    dept = person.get(\"department_raw\")\n",
    "\n",
    "    # 6. role (you already extracted earlier)\n",
    "    role = person.get(\"role\")\n",
    "\n",
    "    # 7. publication count\n",
    "    pubs = person.get(\"publications\", {})\n",
    "    pub_count = pubs.get(\"count\", 0) if isinstance(pubs, dict) else 0\n",
    "\n",
    "     # 8. latest publication date (take max over all publicationDate.date)\n",
    "    latest_pub = None\n",
    "    if isinstance(pubs, dict):\n",
    "        results = pubs.get(\"results\", [])\n",
    "        dates = []\n",
    "        for p in results:\n",
    "            pub_info = p.get(\"publication\", {}) or {}\n",
    "            pub_date_obj = pub_info.get(\"publicationDate\") or {}\n",
    "            date_str = pub_date_obj.get(\"date\")   # e.g. \"2025-02-01\"\n",
    "            if date_str:\n",
    "                dates.append(date_str)\n",
    "        if dates:\n",
    "            latest_pub = max(dates)\n",
    "\n",
    "    \n",
    "\n",
    "    #9. overview\n",
    "    overview = person.get(\"overview\")\n",
    "\n",
    "    # add row\n",
    "    rows.append({\n",
    "        \"researcher_id\": rid,\n",
    "        \"first_name\": first,\n",
    "        \"last_name\": last,\n",
    "        \"full_name\": full,\n",
    "        \"email\": email,\n",
    "        \"title\": title,\n",
    "        \"department_raw\": dept,\n",
    "        \"role\": role,\n",
    "        \"overview\": overview,\n",
    "        \"pub_count\": pub_count,\n",
    "        \"latest_pub_date\": latest_pub,\n",
    "    \n",
    "    })\n",
    "\n",
    "# convert to DataFrame\n",
    "researcher_df = pd.DataFrame(rows)\n",
    "\n",
    "researcher_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b65d3-06a4-4975-90b5-a5bca5f3c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate table two: publication table \n",
    "# step one - original publication-author \n",
    "import pandas as pd\n",
    "\n",
    "pub_rows = []\n",
    "\n",
    "for person in data:  # data is your list of researchers\n",
    "    \n",
    "    # researcher basic info\n",
    "    researcher_id = person.get(\"unique_id\")\n",
    "    first = person.get(\"firstName\")\n",
    "    last = person.get(\"lastName\")\n",
    "    full_name = f\"{first} {last}\".strip() if first or last else None\n",
    "    \n",
    "    # publications block\n",
    "    pubs = person.get(\"publications\", {})\n",
    "    if isinstance(pubs, dict):\n",
    "        results = pubs.get(\"results\", [])\n",
    "    else:\n",
    "        results = []\n",
    "    \n",
    "    # loop over each publication for this researcher\n",
    "    for p in results:\n",
    "        raw_pub_id = p.get(\"id\")\n",
    "        pub_info = p.get(\"publication\", {}) or {}\n",
    "        \n",
    "        pub_title = pub_info.get(\"title\")\n",
    "        pub_abstract = pub_info.get(\"abstract\")\n",
    "        pub_doi = pub_info.get(\"doi\")\n",
    "        \n",
    "        all_authors_obj = pub_info.get(\"allAuthors\", {}) or {}\n",
    "        all_authors = all_authors_obj.get(\"fullList\")\n",
    "\n",
    "            # NEW: extract publicationDate\n",
    "        # structure is like:  \"publicationDate\": {\"date\": \"2025-02-01\"}\n",
    "        date_obj = pub_info.get(\"publicationDate\", {}) or {}\n",
    "        pub_date = date_obj.get(\"date\")   # may be None\n",
    "\n",
    "        \n",
    "        pub_rows.append({\n",
    "            \"raw_pub_id\": raw_pub_id,\n",
    "            \"researcher_id\": researcher_id,\n",
    "            \"full_name\": full_name,\n",
    "            \"pub_title\": pub_title,\n",
    "            \"pub_abstract\": pub_abstract,\n",
    "            \"pub_doi\": pub_doi,\n",
    "            \"all_authors\": all_authors,\n",
    "            \"pub_date\":pub_date\n",
    "        })\n",
    "\n",
    "# build the publication DataFrame\n",
    "raw_pub_df = pd.DataFrame(pub_rows)\n",
    "\n",
    "# 快速看一下前几行\n",
    "raw_pub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e62453-43aa-4e86-af5f-ce8f1e8d3f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68faf9-9487-4341-8b55-a63160bdd451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate table two: publication table \n",
    "import pandas as pd\n",
    "from nanoid import generate\n",
    "\n",
    "\n",
    "clean_pub = raw_pub_df.dropna(subset=[\"pub_title\"]).copy()\n",
    "\n",
    "grouped = clean_pub.groupby(\"pub_title\")\n",
    "\n",
    "new_pub_rows = []\n",
    "\n",
    "for title, group in grouped:\n",
    "\n",
    "    pub_unique_id = generate(size=12)\n",
    "\n",
    "    duke_authors = \"; \".join(group[\"full_name\"].dropna().unique())\n",
    "\n",
    "    raw_pub_ids = list(group[\"raw_pub_id\"].dropna().unique())\n",
    "\n",
    "    pub_abstract = group[\"pub_abstract\"].iloc[0]\n",
    "    pub_doi = group[\"pub_doi\"].iloc[0]\n",
    "    pub_date = group[\"pub_date\"].iloc[0]\n",
    "\n",
    "    new_pub_rows.append({\n",
    "        \"pub_unique_id\": pub_unique_id,\n",
    "        \"pub_title\": title,\n",
    "        \"duke_authors\": duke_authors,\n",
    "        \"raw_pub_ids\": raw_pub_ids,          \n",
    "        \"pub_abstract\": pub_abstract,\n",
    "        \"pub_doi\": pub_doi,\n",
    "        \"pub_date\": pub_date\n",
    "    })\n",
    "\n",
    "publication_clean_df = pd.DataFrame(new_pub_rows)\n",
    "\n",
    "publication_clean_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba730f-a0c7-40de-ab6d-8955aaf405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create coauthorship table \n",
    "# step one (create a table one row per pub_id + researcher pairs (not dedepulicated) \n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "author_pub = raw_pub_df[[\n",
    "    \"pub_title\",\n",
    "    \"researcher_id\",\n",
    "    \"full_name\"\n",
    "]].dropna(subset=[\"pub_title\", \"researcher_id\"])\n",
    "\n",
    "author_pub = author_pub.merge(\n",
    "    publication_clean_df[[\"pub_unique_id\", \"pub_title\"]],\n",
    "    on=\"pub_title\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Total author–pub rows:\", len(author_pub))\n",
    "print(\"Unique publication_unique_id:\", author_pub[\"pub_unique_id\"].nunique())\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for uid, group in author_pub.groupby(\"pub_unique_id\"):\n",
    "    authors = group.to_dict(\"records\")\n",
    "\n",
    "    if len(authors) < 2:\n",
    "        continue\n",
    "\n",
    "    for a, b in combinations(authors, 2):\n",
    "\n",
    "        if a[\"researcher_id\"] < b[\"researcher_id\"]:\n",
    "            left, right = a, b\n",
    "        else:\n",
    "            left, right = b, a\n",
    "\n",
    "        if left[\"researcher_id\"] == right[\"researcher_id\"]:\n",
    "            continue\n",
    "\n",
    "        pairs.append({\n",
    "            \"pub_unique_id\": uid,\n",
    "            \"researcher_A_id\": left[\"researcher_id\"],\n",
    "            \"researcher_B_id\": right[\"researcher_id\"],\n",
    "            \"researcher_A_name\": left[\"full_name\"],\n",
    "            \"researcher_B_name\": right[\"full_name\"]\n",
    "        })\n",
    "\n",
    "coauthor_pairs = pd.DataFrame(pairs)\n",
    "\n",
    "print(\"Total raw coauthor pairs:\", len(coauthor_pairs))\n",
    "coauthor_pairs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b335be4-7b6d-4586-a71c-c1fcd1b32c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db56f72-64e9-45ef-bdd1-dbe65cc06f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create coauthorship table\n",
    "# step two (created the deduplicated pairs with their joint pub counts)\n",
    "coauthor_pairs_final = (\n",
    "    coauthor_pairs\n",
    "        .groupby(\n",
    "            [\"researcher_A_id\", \"researcher_B_id\"],\n",
    "            as_index=False\n",
    "        )\n",
    "        .agg({\n",
    "            \"pub_unique_id\": \"nunique\",          \n",
    "            \"researcher_A_name\": \"first\",        \n",
    "            \"researcher_B_name\": \"first\"\n",
    "        })\n",
    "        .rename(columns={\"pub_unique_id\": \"joint_publications\"})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391eb7c1-35c6-4244-be5b-98f8a39a5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_pairs_final.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6251e-22c2-421c-84f4-55a7522fcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyreadr\n",
    "import pyreadr\n",
    "\n",
    "pyreadr.write_rds(\"researcher_df.rds\", researcher_df)\n",
    "pyreadr.write_rds(\"publication_clean_df.rds\", publication_clean_df)\n",
    "pyreadr.write_rds(\"coauthor_pairs_final.rds\", coauthor_pairs_final)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
