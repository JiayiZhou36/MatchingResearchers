{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23c902-7f8b-4b90-9563-1ce94e9a8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.feather as feather\n",
    "\n",
    "raw_pub_df = feather.read_feather(\"publication_author_per_row.feather\")\n",
    "researcher_df = feather.read_feather(\"researcher_df.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332549e-b37e-4353-bfb7-0332f3b8c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099dc97-d725-40ee-9531-58dbca5b59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e2e0e-869a-491d-a0a9-43abc7ad7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "# 2. Parameters\n",
    "CHUNK_SIZE = 5000  \n",
    "BATCH_SIZE = 64     \n",
    "\n",
    "df = raw_pub_df.copy()   # or samp_df if you're using a smaller set\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "all_embeddings = []   # store results chunk by chunk\n",
    "\n",
    "# 3. Loop over dataframe in chunks\n",
    "for start in tqdm(range(0, len(df), CHUNK_SIZE)):\n",
    "    end = start + CHUNK_SIZE\n",
    "    \n",
    "    chunk = df.iloc[start:end]\n",
    "    abstracts = chunk[\"pub_abstract\"].fillna(\"\").tolist()\n",
    "\n",
    "    # Encode one chunk\n",
    "    emb = model.encode(\n",
    "        abstracts,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    all_embeddings.append(emb)\n",
    "\n",
    "# 4. Stack all chunks together\n",
    "all_embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "# 5. Save back to df\n",
    "df[\"embeddings\"] = list(all_embeddings)\n",
    "\n",
    "print(\"Done! Embedding dimension:\", all_embeddings[0].shape[0])\n",
    "print(\"Total rows embedded:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea3be4-ef88-4e41-bc40-b703bee5e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 1. Compute researcher-level embeddings =====\n",
    "\n",
    "rows = []\n",
    "\n",
    "for rid, group in df.groupby(\"researcher_id\"):\n",
    "    # Stack all embedding vectors for this researcher\n",
    "    mat = np.vstack(group[\"embeddings\"].values)\n",
    "\n",
    "    # Average to get researcher-level embedding\n",
    "    mean_emb = mat.mean(axis=0)\n",
    "\n",
    "    rows.append({\n",
    "        \"researcher_id\": rid,\n",
    "        \"embedding\": mean_emb\n",
    "    })\n",
    "\n",
    "researcher_emb_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Number of researchers with embeddings:\", len(researcher_emb_df))\n",
    "researcher_emb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d194ab-44da-4a16-a961-0acd04e4aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_df_with_emb = researcher_df.merge(\n",
    "    researcher_emb_df,\n",
    "    on=\"researcher_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Merged researcher_df with embeddings.\")\n",
    "researcher_df_with_emb.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a625d-4262-414f-b908-98470abbfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_df_with_emb = researcher_df_with_emb.drop(columns=[\"email\"])\n",
    "researcher_df_with_emb = researcher_df_with_emb[researcher_df_with_emb[\"pub_count\"] != 0].copy()\n",
    "feather.write_feather(researcher_df_with_emb, \"researcher_df_with_emb_new.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770363bd-d697-4585-8c29-63acd10474a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert embedding column to 2D numpy matrix\n",
    "emb_matrix = np.vstack(researcher_df_with_emb['embedding'].values)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_matrix = model.similarity(emb_matrix, emb_matrix)\n",
    "\n",
    "# Convert to DataFrame\n",
    "similarity_id_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=researcher_df_with_emb['researcher_id'],\n",
    "    columns=researcher_df_with_emb['researcher_id']\n",
    ")\n",
    "\n",
    "similarity_id_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f810c-d871-45c8-8efb-e64cc76bc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_id_df.to_feather(\"similarity_id_df.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
