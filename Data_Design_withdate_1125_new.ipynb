{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89083c0d-17e1-4fbd-8045-43b4365a08a3",
   "metadata": {},
   "source": [
    "Data design:\n",
    "This code is for basic data design and cleaning. The objective is to generate three tables from the raw full dataset-JSON data. \n",
    "\n",
    "We plan to generate three tables from the raw JSON data:\n",
    "\n",
    "1. Researcher table: researcher_df \n",
    "This table contains one row per researcher.\n",
    "Required fields include: \n",
    "\"researcher_id\": a unique identifier for each researcher; \n",
    "\"first_name\"; \n",
    "\"last_name\"; \n",
    "\"email\"; \n",
    "\"title\"; \n",
    "\"overview\":\n",
    "\"department_raw\" (parsed from the title directly before cleaning); \n",
    "\"role\": the role of this research in Duke University(for example, professor, assistant professor, graduate student, etc.)The role field for each researcher is determined through a two-stage extraction pipeline. The general principle is: use the primaryAppointment.title first; if that fails, fall back to parsing the overview text. All matching is case-insensitive unless otherwise specified.\n",
    "pub_count: the overall amounts of publication of this researcher;\n",
    "latest_pub_date: the newest publication date.\n",
    "\n",
    "\n",
    "2. Publication table: publication_clean_df \n",
    "****** There are a total of 481,572 author–publication rows, but the number of orginal pub_id(pulled out directly from duke database)'s  values is also 481,572. This means that each pub_id appears only once, and there is no case where two authors share the same pub_id. Therefore, pub_id cannot be used as an indicator of co-authorship, because it does not represent shared publications among multiple researchers. \n",
    "\n",
    "****** In this case, use \"title to create unique_ids and coauthor pairs. (After testing, there is no missing in titles)\n",
    "\n",
    "this table contains one row per publication.\n",
    "Required fields include:\n",
    "\n",
    "\"pub_unique_id\": the unique_id we created by titles. \n",
    "\"researcher_id\": researcher_id,\n",
    "\"researcher_full_name\": first_name,\n",
    "\"pub_title\": pub_title,\n",
    "\"pub_abstract\": pub_abstract,\n",
    "\"pub_doi\": pub_doi,\n",
    "\"duke_authors\": All Duke-affiliated authors matched from the Duke researcher database.\n",
    "\"raw_pub_ids\": All original pub_id values associated with this publication in the Duke source data.\n",
    "\"all_authors\": all_authors, including people who are not matched via Duke database,\n",
    "\"pub_date\": the date this research was published. \n",
    "\n",
    "\n",
    "3. Coauthor relationship: coauthor_pairs_final  \n",
    "This table contains one row per co-author pair. \n",
    "Based on the unique_ids we used \"title\" to create, we created the deduplicated author.\n",
    "Required fields include:\n",
    "Researcher_A_id,\n",
    "Researcher_B_id,\n",
    "Researcher_A_name,\n",
    "Researcher_B_name,\n",
    "joint_pub_numbers: how many publications they collaborated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad6a8e-9cc6-4912-8f39-9fb2be5b3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "!pip install nanoid\n",
    "from nanoid import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432bab4-2b96-4bfb-aa30-fb52bbd41890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import json\n",
    "\n",
    "with open(\"people_2025-11-25_13-57-52.json\", \"r\") as f:\n",
    "    data_dict = json.load(f)\n",
    "data = data_dict[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626feb98-271c-4cb6-bfca-91939d98b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data strcuture\n",
    "def print_json_structure(d, indent=0):\n",
    "    prefix = \"  \" * indent\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(f\"{prefix}{k}: ({type(v).__name__})\")\n",
    "            print_json_structure(v, indent + 1)\n",
    "    elif isinstance(d, list):\n",
    "        print(f\"{prefix}[list of length {len(d)}]\")\n",
    "        if len(d) > 0:\n",
    "            print_json_structure(d[0], indent + 1)\n",
    "    else:\n",
    "        # primitive value -> 不展开\n",
    "        print(f\"{prefix}{d} ({type(d).__name__})\")\n",
    "\n",
    "print_json_structure(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2ffc5-aecd-4064-9503-2ab2b3fb39e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need to figure out what the 'currentResearch' refers to.\n",
    "for i in range(10):\n",
    "    print(data[i]['currentResearch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00895b2d-7221-4654-87de-41830af69027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2c2dd-54a9-4b9e-a383-d32979c17503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(9999)\n",
    "\n",
    "def stable_id():\n",
    "    return hex(random.getrandbits(64))[2:]\n",
    "\n",
    "# data is already a list of researchers\n",
    "print(type(data), len(data))  # just to confirm\n",
    "\n",
    "for person in data:\n",
    "    person[\"unique_id\"] = stable_id()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ae9a963-a6c4-432b-9b3e-6a1dc80a5877",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Role Extraction Logic \n",
    "\n",
    "The role field for each researcher is determined through a two-stage extraction pipeline. The general principle is:\n",
    "use the primaryAppointment.title first; if that fails, fall back to parsing the overview text.\n",
    "All matching is case-insensitive unless otherwise specified.\n",
    "    1. Extraction from primaryAppointment.title (Primary Source)\n",
    "\n",
    "If a researcher has a non-empty primaryAppointment.title, this field is treated as the most reliable indicator of academic rank or position.\n",
    "The title is normalized to lowercase, and the following ordered rules are applied:\n",
    "\n",
    "(1) Emeritus/Emerita detection (highest priority)\n",
    "\n",
    "If the title contains “emeritus” or “emerita”, the role is assigned accordingly (e.g., \"Professor Emeritus\").\n",
    "\n",
    "(2) Visiting appointments\n",
    "\n",
    "If the title includes “visiting”, the role becomes either:\n",
    "\n",
    "\"Visiting Professor\" (if “professor” also appears), or\n",
    "\n",
    "\"Visiting Faculty\" (otherwise).\n",
    "\n",
    "(3) In Residence roles\n",
    "\n",
    "Titles containing “in residence” are categorized based on preceding keywords such as:\n",
    "\n",
    "\"Executive in Residence\"\n",
    "\n",
    "\"Artist in Residence\"\n",
    "\n",
    "\"Scholar in Residence\"\n",
    "\n",
    "(4) Standard faculty ranks\n",
    "\n",
    "Roles are assigned based on the presence of specific rank descriptors:\n",
    "\n",
    "\"Associate Professor\"\n",
    "\n",
    "\"Assistant Professor\"\n",
    "\n",
    "\"Professor\"\n",
    "\n",
    "\"Clinical Professor\" / \"Clinical Faculty\"\n",
    "\n",
    "\"Research Professor\"\n",
    "\n",
    "\"Adjunct Professor\"\n",
    "The matching is done in a prioritized order (associate > assistant > professor, etc.).\n",
    "\n",
    "(5) Lecturer / Instructor / Fellow\n",
    "\n",
    "If none of the above apply, roles may be assigned based on:\n",
    "\n",
    "\"Lecturer\" or \"Lecturing Fellow\"\n",
    "\n",
    "\"Instructor\"\n",
    "\n",
    "(6) Fallback\n",
    "\n",
    "If no rule matches, the role remains None and the overview text is used in the next stage.\n",
    "\n",
    "2. Extraction from overview (Fallback Source)\n",
    "\n",
    "If the role is still None after title-based matching, the researcher’s overview text is parsed using case-insensitive regular expressions. The extraction follows a priority order to prevent overly broad matches (such as “student”) from overriding more specific roles.\n",
    "\n",
    "Priority order for overview-based extraction:\n",
    "(1) PhD-level graduate roles\n",
    "\n",
    "Detected via patterns such as:\n",
    "\n",
    "\"Ph.D. Candidate\"\n",
    "\n",
    "\"PhD Candidate\"\n",
    "\n",
    "\"PhD Student\"\n",
    "\n",
    "\"Doctoral Student\"\n",
    "These all map to:\n",
    "\"PhD Candidate\"\n",
    "\n",
    "(2) Graduate Student\n",
    "\n",
    "Matches \"Graduate Student\" → \"Graduate Student\"\n",
    "\n",
    "(3) Director (capital D only)\n",
    "\n",
    "To avoid false positives, only \"Director\" with capital D is matched → \"Director\"\n",
    "\n",
    "(4) Student (lowest priority)\n",
    "\n",
    "As the final fallback, occurrences of \"student\" assign:\"Student\"\n",
    "\n",
    "This rule is only evaluated if none of the more specific patterns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d8144-da22-4be2-a8b1-11c2ffe5fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role extraction from \"PrimaryAppionment[title]\n",
    "\n",
    "import re\n",
    "\n",
    "def get_role_phrase(raw_title: str):\n",
    "    \"\"\"Extract the role phrase before 'in/of/at' or comma.\"\"\"\n",
    "    if not raw_title:\n",
    "        return None\n",
    "    t = raw_title.strip()\n",
    "    m = re.match(r'^(.*?)(?:\\s+(?:in|of|at)\\b|,)', t, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def normalize_role(raw_title: str):\n",
    "    \"\"\"Normalize academic role titles into a standard label.\"\"\"\n",
    "    if not raw_title:\n",
    "        return None\n",
    "    \n",
    "    # Step 1: extract core role phrase\n",
    "    t = get_role_phrase(raw_title)\n",
    "    if not t:\n",
    "        return None\n",
    "    s = t.strip()\n",
    "\n",
    "    # --- Matching rules in priority order ---\n",
    "\n",
    "    # Emeritus/Emerita\n",
    "    if re.search(r'\\bProfessor\\b.*\\bEmerit', s, flags=re.I):\n",
    "        return 'Professor Emeritus'\n",
    "\n",
    "    # Professor of the Practice\n",
    "    if re.search(r'\\bProfessor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Professor of the Practice'\n",
    "    if re.search(r'\\bAssociate\\s+Professor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Associate Professor of the Practice'\n",
    "    if re.search(r'\\bAssistant\\s+Professor\\s+of\\s+the\\s+Practice\\b', s, flags=re.I):\n",
    "        return 'Assistant Professor of the Practice'\n",
    "\n",
    "    # Special prefixes\n",
    "    if re.search(r'\\bAdjunct\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Adjunct Professor'\n",
    "    if re.search(r'\\bClinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Clinical Professor'\n",
    "    if re.search(r'\\bResearch\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Research Professor'\n",
    "    if re.search(r'\\bVisiting\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Visiting Professor'\n",
    "    \n",
    "    # Medical titles\n",
    "    if re.search(r'\\bMedical\\s+Assistant\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Assistant Professor'\n",
    "    if re.search(r'\\bMedical\\s+Associate\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Associate Professor'\n",
    "    if re.search(r'\\bMedical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Medical Professor'\n",
    "\n",
    "    # Standard professor ranks\n",
    "    if re.search(r'\\bAssociate\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Associate Professor'\n",
    "    if re.search(r'\\bAssistant\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Assistant Professor'\n",
    "    if re.search(r'\\bProfessor\\b', s, flags=re.I):\n",
    "        return 'Professor'\n",
    "\n",
    "    # Clinical roles\n",
    "    if re.search(r'\\bClinical\\s+Faculty\\b', s, flags=re.I):\n",
    "        return 'Clinical Faculty'\n",
    "    if re.search(r'\\bAssociate\\s+Clinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Associate Clinical Professor'\n",
    "    if re.search(r'\\bAssistant\\s+Clinical\\s+Professor\\b', s, flags=re.I):\n",
    "        return 'Assistant Clinical Professor'\n",
    "    if re.search(r'\\bClinical\\s+Associate\\b', s, flags=re.I):\n",
    "        return 'Clinical Associate'\n",
    "    if re.search(r'\\bClinical\\s+Affiliate\\b', s, flags=re.I):\n",
    "        return 'Clinical Affiliate'\n",
    "\n",
    "    # Lecturer / Fellow\n",
    "    if re.search(r'\\bSenior\\s+Lecturing\\s+Fellow\\b', s, flags=re.I):\n",
    "        return 'Senior Lecturing Fellow'\n",
    "    if re.search(r'\\bLecturing\\s+Fellow\\b', s, flags=re.I):\n",
    "        return 'Lecturing Fellow'\n",
    "    if re.search(r'\\bSenior\\s+Lecturer\\b', s, flags=re.I):\n",
    "        return 'Senior Lecturer'\n",
    "    if re.search(r'\\bLecturer\\b', s, flags=re.I):\n",
    "        return 'Lecturer'\n",
    "\n",
    "    # Instructor family\n",
    "    if re.search(r'\\bMedical\\s+Instructor\\b', s, flags=re.I):\n",
    "        return 'Medical Instructor'\n",
    "    if re.search(r'\\bInstructor\\b', s, flags=re.I):\n",
    "        return 'Instructor'\n",
    "\n",
    "    # In Residence / Artist in Residence / Scholar in Residence\n",
    "    if re.search(r'\\bExecutive\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Executive in Residence'\n",
    "    if re.search(r'\\bArtist\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Artist in Residence'\n",
    "    if re.search(r'\\bScholar\\s+In\\s+Residence\\b', s, flags=re.I):\n",
    "        return 'Scholar in Residence'\n",
    "\n",
    "    # Fallback: return original phrase\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64ea04-e47f-4fa0-b554-2d8bb7d847df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: extract title from primaryAppointment\n",
    "def extract_pa_title(pa):\n",
    "    if isinstance(pa, dict):\n",
    "        return pa.get(\"title\")\n",
    "    return None\n",
    "\n",
    "# Step 2: add the new field to each researcher dict\n",
    "for person in data:   # data is your full JSON list\n",
    "    pa_title = extract_pa_title(person.get(\"primaryAppointment\"))\n",
    "    role = normalize_role(pa_title)  # use the function we defined earlier\n",
    "    person[\"role\"] = role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5b3f0-0f41-4d6d-9fe1-941ec7486a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the role is null, continue to fill the role with \"overview\"\n",
    "\n",
    "import re\n",
    "\n",
    "# 1. Regex pattern for roles in overview (case-insensitive)\n",
    "role_pattern_overview = re.compile(\n",
    "    r\"(\"\n",
    "    r\"ph\\.?\\s*d\\.?\\s*candidate|\"        # PhD Candidate / Ph.D. Candidate\n",
    "    r\"ph\\.?\\s*d\\.?\\s*student|\"          # PhD Student / Ph.D. Student\n",
    "    r\"doctoral\\s+student|\"                # Doctoral Student\n",
    "    r\"master'?s?\\s+student|\"              # master's student / masters student\n",
    "    r\"m\\.?\\s*s\\.?\\s*student|\"           # M.S. student / MS student\n",
    "    r\"master\\s+student|\"                  # Master student\n",
    "    r\"graduate\\s+student|\"                # Graduate student\n",
    "    r\"\\bdirector\\b\"                      # Director\n",
    "    r\")\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# 2. Fill role from overview ONLY when existing role is None\n",
    "filled_from_overview = 0\n",
    "\n",
    "for person in data:\n",
    "    # Only try overview if role is currently None\n",
    "    if person.get(\"role\") is None:\n",
    "        overview = person.get(\"overview\") or \"\"\n",
    "        \n",
    "        # Search in overview text\n",
    "        match = role_pattern_overview.search(overview)\n",
    "        if match:\n",
    "            # Use the matched string as role (keep original casing from overview)\n",
    "            person[\"role\"] = match.group(0).strip()\n",
    "            filled_from_overview += 1\n",
    "\n",
    "print(\"Number of roles filled from overview:\", filled_from_overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3d3f5-5bea-4e43-ba4c-d9f580c0efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# department/major \n",
    "import re\n",
    "\n",
    "def extract_department_from_title(primary_appointment):\n",
    "    \"\"\"\n",
    "    primary_appointment is either:\n",
    "      - None\n",
    "      - dict like {\"title\": \"Assistant Professor in ...\"}\n",
    "    \"\"\"\n",
    "    # 1. If no primaryAppointment\n",
    "    if primary_appointment is None:\n",
    "        return None\n",
    "    \n",
    "    # 2. Extract string from {\"title\": \"...\"} \n",
    "    if isinstance(primary_appointment, dict):\n",
    "        title = primary_appointment.get(\"title\", None)\n",
    "    else:\n",
    "        # fallback: if it's already a string\n",
    "        title = primary_appointment\n",
    "    \n",
    "    if not isinstance(title, str):\n",
    "        return None\n",
    "    \n",
    "    t = title.strip()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    lower = t.lower()\n",
    "\n",
    "    # --- extraction rules ---\n",
    "    idx_in = lower.rfind(\" in \")\n",
    "    if idx_in != -1:\n",
    "        dept = t[idx_in + len(\" in \"):].strip()\n",
    "    else:\n",
    "        idx_of = lower.rfind(\" of \")\n",
    "        if idx_of != -1:\n",
    "            dept = t[idx_of + len(\" of \"):].strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # remove \"the \"\n",
    "    dept = re.sub(r\"^\\s*the\\s+\", \"\", dept, flags=re.IGNORECASE)\n",
    "\n",
    "    # remove prefixes\n",
    "    dept = re.sub(r\"^(Department|Division|School|Program|Centre|Center)\\s+of\\s+\", \"\", dept, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # Handle \"Department of X\" inside string\n",
    "    m = re.search(r\"Department\\s+of\\s+(.+)\", dept, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        dept = m.group(1).strip()\n",
    "\n",
    "    # Handle \"School of Nursing\" → \"Nursing\"\n",
    "    m2 = re.search(r\"School\\s+of\\s+(.+)\", dept, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        dept = m2.group(1).strip()\n",
    "\n",
    "    return dept if dept else None\n",
    "\n",
    "\n",
    "# --- Attach to your data ---\n",
    "for person in data:\n",
    "    person[\"department_raw\"] = extract_department_from_title(person.get(\"primaryAppointment\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34bdde-d2fd-4a09-b460-3b384b23e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate table one: researcher table \n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for person in data:   # data is your list of 11547 researchers\n",
    "\n",
    "    # 1. unique researcher id\n",
    "    rid = person.get(\"unique_id\")\n",
    "\n",
    "    # 2. name fields\n",
    "    first = person.get(\"firstName\")\n",
    "    last = person.get(\"lastName\")\n",
    "    full = f\"{first} {last}\".strip() if first or last else None\n",
    "\n",
    "    # 3. email\n",
    "    email = person.get(\"email\")\n",
    "\n",
    "    # 4. primary appointment title\n",
    "    pa = person.get(\"primaryAppointment\")\n",
    "    if isinstance(pa, dict):\n",
    "        title = pa.get(\"title\")\n",
    "    else:\n",
    "        title = None\n",
    "\n",
    "    # 5. department_raw from your earlier extraction\n",
    "    dept = person.get(\"department_raw\")\n",
    "\n",
    "    # 6. role (you already extracted earlier)\n",
    "    role = person.get(\"role\")\n",
    "\n",
    "    # 7. publication count\n",
    "    pubs = person.get(\"publications\", {})\n",
    "    pub_count = pubs.get(\"count\", 0) if isinstance(pubs, dict) else 0\n",
    "\n",
    "     # 8. latest publication date (take max over all publicationDate.date)\n",
    "    latest_pub = None\n",
    "    if isinstance(pubs, dict):\n",
    "        results = pubs.get(\"results\", [])\n",
    "        dates = []\n",
    "        for p in results:\n",
    "            pub_info = p.get(\"publication\", {}) or {}\n",
    "            pub_date_obj = pub_info.get(\"publicationDate\") or {}\n",
    "            date_str = pub_date_obj.get(\"date\")   # e.g. \"2025-02-01\"\n",
    "            if date_str:\n",
    "                dates.append(date_str)\n",
    "        if dates:\n",
    "            latest_pub = max(dates)\n",
    "\n",
    "    \n",
    "\n",
    "    #9. overview\n",
    "    overview = person.get(\"overview\")\n",
    "\n",
    "    # add row\n",
    "    rows.append({\n",
    "        \"researcher_id\": rid,\n",
    "        \"first_name\": first,\n",
    "        \"last_name\": last,\n",
    "        \"full_name\": full,\n",
    "        \"email\": email,\n",
    "        \"title\": title,\n",
    "        \"department_raw\": dept,\n",
    "        \"role\": role,\n",
    "        \"overview\": overview,\n",
    "        \"pub_count\": pub_count,\n",
    "        \"latest_pub_date\": latest_pub,\n",
    "    \n",
    "    })\n",
    "\n",
    "# convert to DataFrame\n",
    "researcher_df = pd.DataFrame(rows)\n",
    "\n",
    "researcher_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b65d3-06a4-4975-90b5-a5bca5f3c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate table two: publication table \n",
    "# step one - original publication-author  （include duplicated author-pub relationships)\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"\n",
    "    Clean publication titles for consistency.\n",
    "    - Lowercase\n",
    "    - Strip whitespace\n",
    "    - Normalize unicode\n",
    "    - Remove repeated spaces\n",
    "    - Remove trailing punctuation (.,;:)\n",
    "    \"\"\"\n",
    "\n",
    "    if title is None:\n",
    "        return None\n",
    "    \n",
    "    # Normalize unicode (fix accents, weird characters)\n",
    "    title = unicodedata.normalize(\"NFKC\", title)\n",
    "\n",
    "    # Lowercase\n",
    "    title = title.lower()\n",
    "\n",
    "    # Remove extra spaces\n",
    "    title = re.sub(r\"\\s+\", \" \", title).strip()\n",
    "\n",
    "    # Remove trailing punctuation such as \".\", \";\", \":\" \n",
    "    title = re.sub(r\"[.;:]+$\", \"\", title)\n",
    "\n",
    "    return title\n",
    "\n",
    "\n",
    "pub_rows = []\n",
    "\n",
    "for person in data:  # data is your list of researchers\n",
    "\n",
    "    # researcher basic info\n",
    "    researcher_id = person.get(\"unique_id\")\n",
    "    first = person.get(\"firstName\")\n",
    "    last = person.get(\"lastName\")\n",
    "    full_name = f\"{first} {last}\".strip() if first or last else None\n",
    "    \n",
    "    # publications block\n",
    "    pubs = person.get(\"publications\", {})\n",
    "    if isinstance(pubs, dict):\n",
    "        results = pubs.get(\"results\", [])\n",
    "    else:\n",
    "        results = []\n",
    "    \n",
    "    # loop over each publication for this researcher\n",
    "    for p in results:\n",
    "        raw_pub_id = p.get(\"id\")\n",
    "        pub_info = p.get(\"publication\", {}) or {}\n",
    "        \n",
    "        pub_title_raw = pub_info.get(\"title\")\n",
    "        pub_title_clean = clean_title(pub_title_raw)\n",
    "\n",
    "        pub_abstract = pub_info.get(\"abstract\")\n",
    "        pub_doi = pub_info.get(\"doi\")\n",
    "        \n",
    "        all_authors_obj = pub_info.get(\"allAuthors\", {}) or {}\n",
    "        all_authors = all_authors_obj.get(\"fullList\")\n",
    "\n",
    "        # extract publication date\n",
    "        date_obj = pub_info.get(\"publicationDate\", {}) or {}\n",
    "        pub_date = date_obj.get(\"date\")\n",
    "\n",
    "        # append row\n",
    "        pub_rows.append({\n",
    "            \"raw_pub_id\": raw_pub_id,\n",
    "            \"researcher_id\": researcher_id,\n",
    "            \"full_name\": full_name,\n",
    "            \"pub_title_raw\": pub_title_raw,\n",
    "            \"pub_title_clean\": pub_title_clean,\n",
    "            \"pub_abstract\": pub_abstract,\n",
    "            \"pub_doi\": pub_doi,\n",
    "            \"all_authors\": all_authors,\n",
    "            \"pub_date\": pub_date\n",
    "        })\n",
    "\n",
    "# build the publication DataFrame\n",
    "raw_pub_df = pd.DataFrame(pub_rows)\n",
    "\n",
    "### step 2 deduplicate author-pub rows \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Make a copy so we don't modify raw_pub_df in place\n",
    "dedup_pub_df = raw_pub_df.copy()\n",
    "\n",
    "# Parse pub_date as datetime (invalid or missing dates become NaT)\n",
    "dedup_pub_df[\"pub_date_parsed\"] = pd.to_datetime(\n",
    "    dedup_pub_df[\"pub_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Helper flag: True if this row has a valid date, False otherwise\n",
    "dedup_pub_df[\"has_date\"] = dedup_pub_df[\"pub_date_parsed\"].notna()\n",
    "\n",
    "# Sort so that:\n",
    "# - same (researcher_id, pub_title_clean) group\n",
    "# - rows with a date come BEFORE rows without date\n",
    "# - among rows with dates, the LATEST date comes first\n",
    "dedup_pub_df = dedup_pub_df.sort_values(\n",
    "    by=[\"researcher_id\", \"pub_title_clean\", \"has_date\", \"pub_date_parsed\"],\n",
    "    ascending=[True, True, False, False]  # keep best row at the top of each group\n",
    ")\n",
    "\n",
    "# Now drop duplicates: keep the first row in each (researcher_id, pub_title_clean) group\n",
    "dedup_pub_df = dedup_pub_df.drop_duplicates(\n",
    "    subset=[\"researcher_id\", \"pub_title_clean\"],\n",
    "    keep=\"first\"\n",
    ")\n",
    "\n",
    "# Drop helper columns\n",
    "dedup_pub_df = dedup_pub_df.drop(columns=[\"pub_date_parsed\", \"has_date\"])\n",
    "\n",
    "# Optional: check how many rows were removed\n",
    "print(\"Original rows:\", raw_pub_df.shape[0])\n",
    "print(\"After de-duplicating by (researcher_id, pub_title_clean):\", dedup_pub_df.shape[0])\n",
    "\n",
    "raw_pub_df = dedup_pub_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838da6a-0abb-49b7-91ff-73c554ae846e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1529f9-e9c6-4620-8bee-5dce56cf8fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae9d2c-fbea-4321-9e1e-ae6116a7064a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68faf9-9487-4341-8b55-a63160bdd451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate table two: publication table \n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Use global random seed for reproducible IDs\n",
    "random.seed(999999)\n",
    "\n",
    "def stable_id():\n",
    "    # Generate a reproducible pseudo-random hex string ID\n",
    "    return hex(random.getrandbits(64))[2:]\n",
    "\n",
    "\n",
    "clean_pub = raw_pub_df.dropna(subset=[\"pub_title_clean\"]).copy()\n",
    "clean_pub = clean_pub[clean_pub[\"pub_title_clean\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "grouped = clean_pub.groupby(\"pub_title_clean\")\n",
    "\n",
    "new_pub_rows = []\n",
    "\n",
    "for title_clean, group in grouped:\n",
    "    \n",
    "    # Stable ID for this publication (one per cleaned title)\n",
    "    pub_unique_id = stable_id()\n",
    "    \n",
    "    # Unique Duke authors in this group\n",
    "    duke_authors = \"; \".join(group[\"full_name\"].dropna().unique())\n",
    "    \n",
    "    # All raw_pub_id values in this group\n",
    "    raw_pub_ids = list(group[\"raw_pub_id\"].dropna().unique())\n",
    "    \n",
    "    # Representative original (raw) title\n",
    "    pub_title_raw = group[\"pub_title_raw\"].iloc[0]\n",
    "    \n",
    "    # First non-null values for abstract, doi, date\n",
    "    pub_abstract = group[\"pub_abstract\"].iloc[0]\n",
    "    pub_doi = group[\"pub_doi\"].iloc[0]\n",
    "    pub_date = group[\"pub_date\"].iloc[0]\n",
    "    \n",
    "    new_pub_rows.append({\n",
    "        \"pub_unique_id\": pub_unique_id,\n",
    "        \"pub_title_raw\": pub_title_raw,\n",
    "        \"pub_title_clean\": title_clean,\n",
    "        \"duke_authors\": duke_authors,\n",
    "        \"raw_pub_ids\": raw_pub_ids,\n",
    "        \"pub_abstract\": pub_abstract,\n",
    "        \"pub_doi\": pub_doi,\n",
    "        \"pub_date\": pub_date\n",
    "    })\n",
    "\n",
    "publication_clean_df = pd.DataFrame(new_pub_rows)\n",
    "publication_clean_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b15e6e-60b6-4972-a6f0-e48b04deabe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba730f-a0c7-40de-ab6d-8955aaf405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create coauthorship table \n",
    "# step one (create a table one row per pub_id + researcher pairs (not dedepulicated) \n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "author_pub = raw_pub_df[[\n",
    "    \"pub_title_clean\",\n",
    "    \"researcher_id\",\n",
    "    \"full_name\"\n",
    "]].dropna(subset=[\"pub_title_clean\", \"researcher_id\"])\n",
    "\n",
    "author_pub = author_pub.merge(\n",
    "    publication_clean_df[[\"pub_unique_id\", \"pub_title_clean\"]],\n",
    "    on=\"pub_title_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Total author–pub rows:\", len(author_pub))\n",
    "print(\"Unique publication_unique_id:\", author_pub[\"pub_unique_id\"].nunique())\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for uid, group in author_pub.groupby(\"pub_unique_id\"):\n",
    "    authors = group.to_dict(\"records\")\n",
    "\n",
    "    if len(authors) < 2:\n",
    "        continue\n",
    "\n",
    "    for a, b in combinations(authors, 2):\n",
    "\n",
    "        if a[\"researcher_id\"] < b[\"researcher_id\"]:\n",
    "            left, right = a, b\n",
    "        else:\n",
    "            left, right = b, a\n",
    "\n",
    "        if left[\"researcher_id\"] == right[\"researcher_id\"]:\n",
    "            continue\n",
    "\n",
    "        pairs.append({\n",
    "            \"pub_unique_id\": uid,\n",
    "            \"pub_title_cleaned\":pub_title_clean,\n",
    "            \"researcher_A_id\": left[\"researcher_id\"],\n",
    "            \"researcher_B_id\": right[\"researcher_id\"],\n",
    "            \"researcher_A_name\": left[\"full_name\"],\n",
    "            \"researcher_B_name\": right[\"full_name\"]\n",
    "        })\n",
    "\n",
    "coauthor_pairs = pd.DataFrame(pairs)\n",
    "\n",
    "print(\"Total raw coauthor pairs:\", len(coauthor_pairs))\n",
    "coauthor_pairs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b335be4-7b6d-4586-a71c-c1fcd1b32c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db56f72-64e9-45ef-bdd1-dbe65cc06f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create coauthorship table\n",
    "# step two (created the deduplicated pairs with their joint pub counts)\n",
    "coauthor_pairs_final = (\n",
    "    coauthor_pairs\n",
    "        .groupby(\n",
    "            [\"researcher_A_id\", \"researcher_B_id\"],\n",
    "            as_index=False\n",
    "        )\n",
    "        .agg({\n",
    "            \"pub_unique_id\": \"nunique\",          \n",
    "            \"researcher_A_name\": \"first\",        \n",
    "            \"researcher_B_name\": \"first\"\n",
    "        })\n",
    "        .rename(columns={\"pub_unique_id\": \"joint_publications\"})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391eb7c1-35c6-4244-be5b-98f8a39a5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_pairs_final.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6251e-22c2-421c-84f4-55a7522fcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyreadr\n",
    "import pyreadr\n",
    "\n",
    "pyreadr.write_rds(\"researcher_df.rds\", researcher_df)\n",
    "pyreadr.write_rds(\"publication_author_per_row\", raw_pub_df)\n",
    "pyreadr.write_rds(\"publication_clean_df.rds\", publication_clean_df)\n",
    "pyreadr.write_rds(\"coauthor_pairs_final.rds\", coauthor_pairs_final)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
